{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOknqIl5aBZceIbXE/FHOKI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ismat-Samadov/colab_notebooks/blob/main/gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GICxwbSA71tY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e6c420c-a964-4461-c873-507fbc778be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.18.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers tokenizers wandb tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NfYtGWud8d30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from tokenizers import Tokenizer\n",
        "from datetime import datetime\n",
        "import gc\n",
        "class GPTConfig:\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size=22588,\n",
        "        n_embd=768,      # Reduced from 2048\n",
        "        n_head=12,       # Reduced from 16\n",
        "        n_layer=8,       # Reduced from 12\n",
        "        dropout=0.1,\n",
        "        block_size=256,  # Reduced from 512\n",
        "        learning_rate=3e-4,\n",
        "        max_epochs=50,\n",
        "        batch_size=8,    # Reduced from 64\n",
        "        grad_clip=1.0,\n",
        "    ):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.n_embd = n_embd\n",
        "        self.n_head = n_head\n",
        "        self.n_layer = n_layer\n",
        "        self.dropout = dropout\n",
        "        self.block_size = block_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_epochs = max_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.grad_clip = grad_clip\n",
        "\n",
        "# Model Architecture\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        self.w_k = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.w_q = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.w_v = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.attn_drop = nn.Dropout(config.dropout)\n",
        "        self.resid_drop = nn.Dropout(config.dropout)\n",
        "        self.proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size()\n",
        "        k = self.w_k(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        q = self.w_q(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        v = self.w_v(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "\n",
        "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        att = self.attn_drop(att)\n",
        "        y = att @ v\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        y = self.resid_drop(self.proj(y))\n",
        "        return y\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(config.n_embd)\n",
        "        self.attn = SelfAttention(config)\n",
        "        self.ln2 = nn.LayerNorm(config.n_embd)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(config.n_embd, 4 * config.n_embd),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(4 * config.n_embd, config.n_embd),\n",
        "            nn.Dropout(config.dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class GPT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embd)\n",
        "        self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size, config.n_embd))\n",
        "        self.drop = nn.Dropout(config.dropout)\n",
        "        self.blocks = nn.ModuleList([Block(config) for _ in range(config.n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(config.n_embd)\n",
        "        self.head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "\n",
        "        self.block_size = config.block_size\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
        "            if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        b, t = idx.size()\n",
        "        assert t <= self.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.block_size}\"\n",
        "\n",
        "        token_embeddings = self.tok_emb(idx)\n",
        "        position_embeddings = self.pos_emb[:, :t, :]\n",
        "        x = self.drop(token_embeddings + position_embeddings)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.head(x)\n",
        "\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "\n",
        "class WikiTextDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, max_length=256):  # Reduced max_length\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "        print(\"Tokenizing texts...\")\n",
        "        self.examples = []\n",
        "\n",
        "        for text in tqdm(texts):\n",
        "            tokens = self.tokenizer.encode(text).ids\n",
        "            for i in range(0, len(tokens) - max_length, max_length // 2):\n",
        "                chunk = tokens[i:i + max_length]\n",
        "                if len(chunk) < max_length:\n",
        "                    chunk = chunk + [0] * (max_length - len(chunk))\n",
        "                self.examples.append(chunk)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.examples[idx]\n",
        "        return torch.tensor(tokens[:-1]), torch.tensor(tokens[1:])\n",
        "\n",
        "def train():\n",
        "    # Clear GPU memory\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    print(\"Loading Wikipedia data...\")\n",
        "    with open('az_wiki_data.json', 'r', encoding='utf-8') as f:\n",
        "        wiki_data = json.load(f)\n",
        "\n",
        "    texts = [page['text'] for page in wiki_data.values()]\n",
        "    tokenizer = Tokenizer.from_file(\"az_tokenizer.json\")\n",
        "\n",
        "    dataset = WikiTextDataset(texts, tokenizer)\n",
        "    train_size = int(0.9 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    config = GPTConfig()\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,  # Reduced from 4\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2,  # Reduced from 4\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    model = GPT(config)\n",
        "    model = model.to('cuda')\n",
        "    print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=config.max_epochs)\n",
        "    scaler = torch.amp.GradScaler()  # Updated deprecation warning\n",
        "\n",
        "    def run_epoch(split, epoch_num=0):\n",
        "        is_train = split == 'train'\n",
        "        model.train(is_train)\n",
        "        if not is_train:\n",
        "            model.eval()\n",
        "\n",
        "        loader = train_loader if is_train else val_loader\n",
        "        losses = []\n",
        "\n",
        "        pbar = tqdm(enumerate(loader), total=len(loader)) if is_train else enumerate(loader)\n",
        "\n",
        "        for it, (x, y) in pbar:\n",
        "            # Clear memory\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            x = x.to('cuda', non_blocking=True)\n",
        "            y = y.to('cuda', non_blocking=True)\n",
        "\n",
        "            with torch.amp.autocast(device_type='cuda'):  # Updated deprecation warning\n",
        "                logits, loss = model(x, y)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            if is_train:\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip)\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "                pbar.set_description(f\"epoch {epoch_num+1} iter {it}: train loss {loss.item():.5f}\")\n",
        "\n",
        "            # Delete unnecessary tensors\n",
        "            del x, y, logits\n",
        "            if is_train:\n",
        "                del loss\n",
        "\n",
        "        mean_loss = torch.tensor(losses).mean().item()\n",
        "        return mean_loss\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    try:\n",
        "        for epoch in range(config.max_epochs):\n",
        "            print(f\"\\nEpoch {epoch+1}/{config.max_epochs}\")\n",
        "\n",
        "            train_loss = run_epoch('train', epoch_num=epoch)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                val_loss = run_epoch('val')\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                print(f\"Saving best model with val_loss: {val_loss:.4f}\")\n",
        "                torch.save(model.state_dict(), 'best_model.pt')\n",
        "\n",
        "            print(f\"Epoch {epoch+1}: train_loss: {train_loss:.4f}, val_loss: {val_loss:.4f}\")\n",
        "\n",
        "            if (epoch + 1) % 5 == 0:\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'scheduler_state_dict': scheduler.state_dict(),\n",
        "                    'train_loss': train_loss,\n",
        "                    'val_loss': val_loss,\n",
        "                }, f'checkpoint_epoch_{epoch+1}.pt')\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print('Training interrupted, saving checkpoint...')\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss,\n",
        "        }, 'interrupt_checkpoint.pt')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train()"
      ],
      "metadata": {
        "id": "JvyhTo3Q8d1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3fa85af-c2e2-49ec-c8c5-45b330348241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Wikipedia data...\n",
            "Tokenizing texts...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 99.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 91.60M\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 192: train loss 7.05687: 100%|██████████| 193/193 [00:09<00:00, 19.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 7.0814\n",
            "Epoch 1: train_loss: 7.6705, val_loss: 7.0814\n",
            "\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 2 iter 192: train loss 6.34142: 100%|██████████| 193/193 [00:09<00:00, 19.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 6.4779\n",
            "Epoch 2: train_loss: 6.6228, val_loss: 6.4779\n",
            "\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 3 iter 192: train loss 6.27657: 100%|██████████| 193/193 [00:09<00:00, 19.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 6.0565\n",
            "Epoch 3: train_loss: 5.9504, val_loss: 6.0565\n",
            "\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 4 iter 192: train loss 5.07158: 100%|██████████| 193/193 [00:09<00:00, 19.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 5.7152\n",
            "Epoch 4: train_loss: 5.3975, val_loss: 5.7152\n",
            "\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 5 iter 192: train loss 4.58005: 100%|██████████| 193/193 [00:09<00:00, 20.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 5.4316\n",
            "Epoch 5: train_loss: 4.9027, val_loss: 5.4316\n",
            "\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 6 iter 192: train loss 4.14214: 100%|██████████| 193/193 [00:09<00:00, 19.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 5.1546\n",
            "Epoch 6: train_loss: 4.4219, val_loss: 5.1546\n",
            "\n",
            "Epoch 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 7 iter 192: train loss 4.12808: 100%|██████████| 193/193 [00:09<00:00, 19.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 4.9316\n",
            "Epoch 7: train_loss: 3.9554, val_loss: 4.9316\n",
            "\n",
            "Epoch 8/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 8 iter 192: train loss 3.17821: 100%|██████████| 193/193 [00:09<00:00, 19.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 4.6962\n",
            "Epoch 8: train_loss: 3.5010, val_loss: 4.6962\n",
            "\n",
            "Epoch 9/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 9 iter 192: train loss 2.94456: 100%|██████████| 193/193 [00:09<00:00, 20.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 4.5112\n",
            "Epoch 9: train_loss: 3.0461, val_loss: 4.5112\n",
            "\n",
            "Epoch 10/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 10 iter 192: train loss 3.04044: 100%|██████████| 193/193 [00:09<00:00, 19.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 4.2408\n",
            "Epoch 10: train_loss: 2.6048, val_loss: 4.2408\n",
            "\n",
            "Epoch 11/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 11 iter 192: train loss 2.06172: 100%|██████████| 193/193 [00:09<00:00, 19.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 3.9070\n",
            "Epoch 11: train_loss: 2.1653, val_loss: 3.9070\n",
            "\n",
            "Epoch 12/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 12 iter 192: train loss 1.71259: 100%|██████████| 193/193 [00:09<00:00, 19.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 3.5535\n",
            "Epoch 12: train_loss: 1.7550, val_loss: 3.5535\n",
            "\n",
            "Epoch 13/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 13 iter 192: train loss 1.31166: 100%|██████████| 193/193 [00:09<00:00, 19.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 3.0910\n",
            "Epoch 13: train_loss: 1.3600, val_loss: 3.0910\n",
            "\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 14 iter 192: train loss 0.56372: 100%|██████████| 193/193 [00:09<00:00, 20.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 2.0341\n",
            "Epoch 14: train_loss: 0.9023, val_loss: 2.0341\n",
            "\n",
            "Epoch 15/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 15 iter 192: train loss 0.43953: 100%|██████████| 193/193 [00:09<00:00, 19.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 1.1052\n",
            "Epoch 15: train_loss: 0.4319, val_loss: 1.1052\n",
            "\n",
            "Epoch 16/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 16 iter 192: train loss 0.11596: 100%|██████████| 193/193 [00:09<00:00, 20.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.7092\n",
            "Epoch 16: train_loss: 0.1849, val_loss: 0.7092\n",
            "\n",
            "Epoch 17/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 17 iter 192: train loss 0.05657: 100%|██████████| 193/193 [00:09<00:00, 20.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.5287\n",
            "Epoch 17: train_loss: 0.0779, val_loss: 0.5287\n",
            "\n",
            "Epoch 18/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 18 iter 192: train loss 0.03203: 100%|██████████| 193/193 [00:09<00:00, 20.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.4538\n",
            "Epoch 18: train_loss: 0.0381, val_loss: 0.4538\n",
            "\n",
            "Epoch 19/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 19 iter 192: train loss 0.02051: 100%|██████████| 193/193 [00:09<00:00, 19.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.4212\n",
            "Epoch 19: train_loss: 0.0260, val_loss: 0.4212\n",
            "\n",
            "Epoch 20/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 20 iter 192: train loss 0.01742: 100%|██████████| 193/193 [00:09<00:00, 19.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.3935\n",
            "Epoch 20: train_loss: 0.0208, val_loss: 0.3935\n",
            "\n",
            "Epoch 21/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 21 iter 192: train loss 0.03062: 100%|██████████| 193/193 [00:09<00:00, 19.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.3785\n",
            "Epoch 21: train_loss: 0.0179, val_loss: 0.3785\n",
            "\n",
            "Epoch 22/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 22 iter 192: train loss 0.02770: 100%|██████████| 193/193 [00:09<00:00, 20.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.3610\n",
            "Epoch 22: train_loss: 0.0153, val_loss: 0.3610\n",
            "\n",
            "Epoch 23/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 23 iter 192: train loss 0.01108: 100%|██████████| 193/193 [00:09<00:00, 19.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.3465\n",
            "Epoch 23: train_loss: 0.0133, val_loss: 0.3465\n",
            "\n",
            "Epoch 24/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 24 iter 192: train loss 0.00669: 100%|██████████| 193/193 [00:09<00:00, 19.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.3299\n",
            "Epoch 24: train_loss: 0.0114, val_loss: 0.3299\n",
            "\n",
            "Epoch 25/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 25 iter 192: train loss 0.01406: 100%|██████████| 193/193 [00:09<00:00, 19.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.3194\n",
            "Epoch 25: train_loss: 0.0098, val_loss: 0.3194\n",
            "\n",
            "Epoch 26/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 26 iter 192: train loss 0.00476: 100%|██████████| 193/193 [00:09<00:00, 19.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.3071\n",
            "Epoch 26: train_loss: 0.0079, val_loss: 0.3071\n",
            "\n",
            "Epoch 27/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 27 iter 192: train loss 0.00783: 100%|██████████| 193/193 [00:09<00:00, 19.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.3014\n",
            "Epoch 27: train_loss: 0.0068, val_loss: 0.3014\n",
            "\n",
            "Epoch 28/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 28 iter 192: train loss 0.00500: 100%|██████████| 193/193 [00:09<00:00, 19.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.2905\n",
            "Epoch 28: train_loss: 0.0059, val_loss: 0.2905\n",
            "\n",
            "Epoch 29/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 29 iter 192: train loss 0.00480: 100%|██████████| 193/193 [00:09<00:00, 19.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.2836\n",
            "Epoch 29: train_loss: 0.0051, val_loss: 0.2836\n",
            "\n",
            "Epoch 30/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 30 iter 192: train loss 0.00243: 100%|██████████| 193/193 [00:09<00:00, 19.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.2816\n",
            "Epoch 30: train_loss: 0.0042, val_loss: 0.2816\n",
            "\n",
            "Epoch 31/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 31 iter 192: train loss 0.00318: 100%|██████████| 193/193 [00:09<00:00, 19.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.2773\n",
            "Epoch 31: train_loss: 0.0042, val_loss: 0.2773\n",
            "\n",
            "Epoch 32/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 32 iter 192: train loss 0.00248: 100%|██████████| 193/193 [00:09<00:00, 19.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.2703\n",
            "Epoch 32: train_loss: 0.0036, val_loss: 0.2703\n",
            "\n",
            "Epoch 33/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 33 iter 192: train loss 0.00177: 100%|██████████| 193/193 [00:09<00:00, 19.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.2647\n",
            "Epoch 33: train_loss: 0.0032, val_loss: 0.2647\n",
            "\n",
            "Epoch 34/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 34 iter 192: train loss 0.00375: 100%|██████████| 193/193 [00:09<00:00, 19.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.2644\n",
            "Epoch 34: train_loss: 0.0029, val_loss: 0.2644\n",
            "\n",
            "Epoch 35/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 35 iter 192: train loss 0.00101: 100%|██████████| 193/193 [00:09<00:00, 19.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.2589\n",
            "Epoch 35: train_loss: 0.0026, val_loss: 0.2589\n",
            "\n",
            "Epoch 36/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 36 iter 192: train loss 0.00131: 100%|██████████| 193/193 [00:09<00:00, 19.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.2576\n",
            "Epoch 36: train_loss: 0.0025, val_loss: 0.2576\n",
            "\n",
            "Epoch 37/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 37 iter 192: train loss 0.00272: 100%|██████████| 193/193 [00:09<00:00, 20.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.2510\n",
            "Epoch 37: train_loss: 0.0023, val_loss: 0.2510\n",
            "\n",
            "Epoch 38/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 38 iter 192: train loss 0.00414: 100%|██████████| 193/193 [00:09<00:00, 19.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38: train_loss: 0.0022, val_loss: 0.2514\n",
            "\n",
            "Epoch 39/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 39 iter 192: train loss 0.00099: 100%|██████████| 193/193 [00:09<00:00, 19.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.2497\n",
            "Epoch 39: train_loss: 0.0021, val_loss: 0.2497\n",
            "\n",
            "Epoch 40/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 40 iter 192: train loss 0.00350: 100%|██████████| 193/193 [00:09<00:00, 19.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.2494\n",
            "Epoch 40: train_loss: 0.0018, val_loss: 0.2494\n",
            "\n",
            "Epoch 41/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 41 iter 192: train loss 0.00435: 100%|██████████| 193/193 [00:09<00:00, 19.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.2465\n",
            "Epoch 41: train_loss: 0.0019, val_loss: 0.2465\n",
            "\n",
            "Epoch 42/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 42 iter 192: train loss 0.00085: 100%|██████████| 193/193 [00:09<00:00, 20.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42: train_loss: 0.0016, val_loss: 0.2467\n",
            "\n",
            "Epoch 43/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 43 iter 192: train loss 0.00184: 100%|██████████| 193/193 [00:09<00:00, 19.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.2454\n",
            "Epoch 43: train_loss: 0.0016, val_loss: 0.2454\n",
            "\n",
            "Epoch 44/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 44 iter 192: train loss 0.00143: 100%|██████████| 193/193 [00:09<00:00, 19.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.2449\n",
            "Epoch 44: train_loss: 0.0016, val_loss: 0.2449\n",
            "\n",
            "Epoch 45/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 45 iter 192: train loss 0.00090: 100%|██████████| 193/193 [00:09<00:00, 19.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.2445\n",
            "Epoch 45: train_loss: 0.0014, val_loss: 0.2445\n",
            "\n",
            "Epoch 46/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 46 iter 192: train loss 0.00065: 100%|██████████| 193/193 [00:09<00:00, 19.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.2443\n",
            "Epoch 46: train_loss: 0.0015, val_loss: 0.2443\n",
            "\n",
            "Epoch 47/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 47 iter 192: train loss 0.00075: 100%|██████████| 193/193 [00:09<00:00, 19.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.2439\n",
            "Epoch 47: train_loss: 0.0014, val_loss: 0.2439\n",
            "\n",
            "Epoch 48/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 48 iter 192: train loss 0.00082: 100%|██████████| 193/193 [00:09<00:00, 19.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.2437\n",
            "Epoch 48: train_loss: 0.0015, val_loss: 0.2437\n",
            "\n",
            "Epoch 49/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 49 iter 192: train loss 0.00144: 100%|██████████| 193/193 [00:09<00:00, 20.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.2435\n",
            "Epoch 49: train_loss: 0.0014, val_loss: 0.2435\n",
            "\n",
            "Epoch 50/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 50 iter 192: train loss 0.00057: 100%|██████████| 193/193 [00:09<00:00, 19.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model with val_loss: 0.2435\n",
            "Epoch 50: train_loss: 0.0013, val_loss: 0.2435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First import necessary modules and mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create directory for your models\n",
        "!mkdir -p '/content/drive/MyDrive/az_gpt_project'\n",
        "\n",
        "# Copy all existing files from /content to your Drive\n",
        "!cp /content/best_model.pt /content/drive/MyDrive/az_gpt_project/\n",
        "!cp /content/checkpoint_epoch_*.pt /content/drive/MyDrive/az_gpt_project/\n",
        "!cp /content/az_tokenizer.json /content/drive/MyDrive/az_gpt_project/\n",
        "!cp /content/az_wiki_data.json /content/drive/MyDrive/az_gpt_project/\n",
        "\n",
        "# Verify the files were copied\n",
        "!ls /content/drive/MyDrive/az_gpt_project"
      ],
      "metadata": {
        "id": "Jw8ljZ_88dy7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b305220d-e727-4565-b344-fddccaefb5e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "cp: cannot stat '/content/best_model.pt': No such file or directory\n",
            "az_tokenizer.json\tcheckpoint_epoch_15.pt\tcheckpoint_epoch_30.pt\tcheckpoint_epoch_45.pt\n",
            "az_wiki_data.json\tcheckpoint_epoch_20.pt\tcheckpoint_epoch_35.pt\tcheckpoint_epoch_5.pt\n",
            "checkpoint_epoch_10.pt\tcheckpoint_epoch_25.pt\tcheckpoint_epoch_40.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gUchBnZY8dtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UmxFHaUa8dq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hNCArClV8doK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CWKsUV-y8dlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SjI0-oeT8di-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SX_CQEX88dgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UJ99oIz48ddr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9qlpfa0s8dbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I4ZKC94y8dYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xXds1g-R8dV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_rBuQV1C8dTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2imNmBew8dQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fYTp2i3y8dOL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}