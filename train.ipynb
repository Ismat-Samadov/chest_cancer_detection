{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38b7fdf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2899f0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7013e91b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4004c9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Input, GaussianNoise\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define constants\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 15\n",
    "DATA_DIR = \"path/to/your/Data\"  # Update this to your data directory\n",
    "MODEL_PATH = \"chest_ct_binary_classifier.keras\"\n",
    "\n",
    "# Create directory to save models and plots\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "\n",
    "# Define custom preprocessing for advanced augmentation\n",
    "def custom_preprocessing(img):\n",
    "    \"\"\"Apply advanced preprocessing techniques to a single image\"\"\"\n",
    "    # Convert to PIL Image if it's a numpy array\n",
    "    if not isinstance(img, Image.Image):\n",
    "        img = Image.fromarray((img * 255).astype(np.uint8))\n",
    "    \n",
    "    # Randomly apply CLAHE\n",
    "    if np.random.random() < 0.3:\n",
    "        img = ImageOps.equalize(img)\n",
    "    \n",
    "    # Randomly adjust contrast\n",
    "    if np.random.random() < 0.3:\n",
    "        factor = np.random.uniform(0.5, 1.5)\n",
    "        enhancer = ImageEnhance.Contrast(img)\n",
    "        img = enhancer.enhance(factor)\n",
    "    \n",
    "    # Randomly adjust sharpness\n",
    "    if np.random.random() < 0.3:\n",
    "        factor = np.random.uniform(0.5, 2.0)\n",
    "        enhancer = ImageEnhance.Sharpness(img)\n",
    "        img = enhancer.enhance(factor)\n",
    "    \n",
    "    return np.array(img) / 255.0\n",
    "\n",
    "# Create data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=custom_preprocessing,\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    fill_mode='reflect',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Define cancer and normal class paths\n",
    "cancer_classes = [\n",
    "    'adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib',\n",
    "    'large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa',\n",
    "    'squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa'\n",
    "]\n",
    "\n",
    "# Prepare dataframes for the data generators\n",
    "train_files = []\n",
    "train_labels = []\n",
    "valid_files = []\n",
    "valid_labels = []\n",
    "test_files = []\n",
    "test_labels = []\n",
    "\n",
    "# Add normal class\n",
    "for img_file in os.listdir(os.path.join(DATA_DIR, 'train', 'normal')):\n",
    "    if img_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        img_path = os.path.join(DATA_DIR, 'train', 'normal', img_file)\n",
    "        train_files.append(img_path)\n",
    "        train_labels.append(0)  # 0 for normal\n",
    "\n",
    "for img_file in os.listdir(os.path.join(DATA_DIR, 'valid', 'normal')):\n",
    "    if img_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        img_path = os.path.join(DATA_DIR, 'valid', 'normal', img_file)\n",
    "        valid_files.append(img_path)\n",
    "        valid_labels.append(0)  # 0 for normal\n",
    "\n",
    "for img_file in os.listdir(os.path.join(DATA_DIR, 'test', 'normal')):\n",
    "    if img_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        img_path = os.path.join(DATA_DIR, 'test', 'normal', img_file)\n",
    "        test_files.append(img_path)\n",
    "        test_labels.append(0)  # 0 for normal\n",
    "\n",
    "# Add cancer classes (all labeled as 1)\n",
    "for cancer_class in cancer_classes:\n",
    "    # Training data\n",
    "    class_dir = os.path.join(DATA_DIR, 'train', cancer_class)\n",
    "    if os.path.exists(class_dir):\n",
    "        for img_file in os.listdir(class_dir):\n",
    "            if img_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(class_dir, img_file)\n",
    "                train_files.append(img_path)\n",
    "                train_labels.append(1)  # 1 for cancer\n",
    "    \n",
    "    # Validation data\n",
    "    class_dir = os.path.join(DATA_DIR, 'valid', cancer_class)\n",
    "    if os.path.exists(class_dir):\n",
    "        for img_file in os.listdir(class_dir):\n",
    "            if img_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(class_dir, img_file)\n",
    "                valid_files.append(img_path)\n",
    "                valid_labels.append(1)  # 1 for cancer\n",
    "    \n",
    "    # Test data - look for each cancer type in the test directory\n",
    "    test_class_dir = os.path.join(DATA_DIR, 'test', cancer_class.split('_')[0])\n",
    "    if os.path.exists(test_class_dir):\n",
    "        for img_file in os.listdir(test_class_dir):\n",
    "            if img_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(test_class_dir, img_file)\n",
    "                test_files.append(img_path)\n",
    "                test_labels.append(1)  # 1 for cancer\n",
    "\n",
    "# Create dataframes\n",
    "train_df = pd.DataFrame({'filename': train_files, 'class': train_labels})\n",
    "valid_df = pd.DataFrame({'filename': valid_files, 'class': valid_labels})\n",
    "test_df = pd.DataFrame({'filename': test_files, 'class': test_labels})\n",
    "\n",
    "print(f\"Training set: {len(train_df)} images\")\n",
    "print(f\"Validation set: {len(valid_df)} images\")\n",
    "print(f\"Test set: {len(test_df)} images\")\n",
    "print(f\"Training class distribution: {train_df['class'].value_counts()}\")\n",
    "print(f\"Validation class distribution: {valid_df['class'].value_counts()}\")\n",
    "print(f\"Test class distribution: {test_df['class'].value_counts()}\")\n",
    "\n",
    "# Create balanced generators\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_df['class']), y=train_df['class'])\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "print(f\"Class weights: {class_weight_dict}\")\n",
    "\n",
    "# Flow from dataframe\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"class\",\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=valid_df,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"class\",\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"class\",\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Create binary classification model using DenseNet121\n",
    "def create_binary_model():\n",
    "    # Load pre-trained DenseNet121\n",
    "    base_model = DenseNet121(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "    \n",
    "    # Freeze base model initially\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Create model architecture\n",
    "    inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = GaussianNoise(0.1)(inputs)  # Add noise for better generalization\n",
    "    x = base_model(x, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Add regularization layers\n",
    "    x = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    # Binary output\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.AUC(name='auc'),\n",
    "            tf.keras.metrics.Precision(name='precision'),\n",
    "            tf.keras.metrics.Recall(name='recall')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Create and compile the model\n",
    "print(\"Creating model...\")\n",
    "model, base_model = create_binary_model()\n",
    "model.summary()\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_accuracy',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='models/binary_model_checkpoint.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# First phase: Train with frozen base model\n",
    "print(\"Phase 1: Training top layers...\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=len(valid_generator),\n",
    "    epochs=8,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Second phase: Fine-tune by unfreezing some layers\n",
    "print(\"Phase 2: Fine-tuning the model...\")\n",
    "# Unfreeze the top layers of the base model\n",
    "base_model.trainable = True\n",
    "# Keep first 100 layers frozen, unfreeze the rest for fine-tuning\n",
    "for layer in base_model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with lower learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.00001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Continue training\n",
    "fine_tuning_history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=len(valid_generator),\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1,\n",
    "    initial_epoch=len(history.history['loss'])\n",
    ")\n",
    "\n",
    "# Combine histories for plotting\n",
    "history_dict = {}\n",
    "for metric in ['accuracy', 'loss', 'auc', 'precision', 'recall', \n",
    "               'val_accuracy', 'val_loss', 'val_auc', 'val_precision', 'val_recall']:\n",
    "    if metric in history.history and metric in fine_tuning_history.history:\n",
    "        # Handle possible name changes\n",
    "        alt_metric = metric\n",
    "        if metric not in fine_tuning_history.history and f\"{metric}_1\" in fine_tuning_history.history:\n",
    "            alt_metric = f\"{metric}_1\"\n",
    "        \n",
    "        history_dict[metric] = history.history[metric] + fine_tuning_history.history[alt_metric]\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history_dict['accuracy'], label='Train')\n",
    "plt.plot(history_dict['val_accuracy'], label='Validation')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.axvline(x=len(history.history['accuracy'])-1, color='r', linestyle='--', label='Fine-tuning start')\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history_dict['loss'], label='Train')\n",
    "plt.plot(history_dict['val_loss'], label='Validation')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.axvline(x=len(history.history['loss'])-1, color='r', linestyle='--')\n",
    "\n",
    "# Plot AUC\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(history_dict['auc'], label='Train')\n",
    "plt.plot(history_dict['val_auc'], label='Validation')\n",
    "plt.title('AUC')\n",
    "plt.legend()\n",
    "plt.axvline(x=len(history.history['auc'])-1, color='r', linestyle='--')\n",
    "\n",
    "# Plot Precision-Recall\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(history_dict['precision'], label='Train Precision')\n",
    "plt.plot(history_dict['val_precision'], label='Validation Precision')\n",
    "plt.plot(history_dict['recall'], label='Train Recall')\n",
    "plt.plot(history_dict['val_recall'], label='Validation Recall')\n",
    "plt.title('Precision and Recall')\n",
    "plt.legend()\n",
    "plt.axvline(x=len(history.history['precision'])-1, color='r', linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/training_history.png')\n",
    "\n",
    "# Evaluate the model on test set\n",
    "print(\"Evaluating model on test set...\")\n",
    "test_results = model.evaluate(test_generator, verbose=1)\n",
    "print(f\"Test results: {dict(zip(model.metrics_names, test_results))}\")\n",
    "\n",
    "# Save the model in different formats\n",
    "print(f\"Saving model...\")\n",
    "\n",
    "# Save model in Keras format\n",
    "model.save(f'models/{MODEL_PATH}')\n",
    "print(f\"Model saved as models/{MODEL_PATH}\")\n",
    "\n",
    "# Save model in TFLite format for mobile/edge deployment\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "with open('models/chest_ct_binary_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "print(\"TFLite model saved as models/chest_ct_binary_model.tflite\")\n",
    "\n",
    "# Create a simple function to test the model with a single image\n",
    "def predict_cancer(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    prediction = model.predict(img_array)[0][0]\n",
    "    class_name = \"Cancer\" if prediction > 0.5 else \"Normal\"\n",
    "    confidence = prediction if prediction > 0.5 else 1 - prediction\n",
    "    \n",
    "    return {\n",
    "        \"prediction\": class_name,\n",
    "        \"confidence\": float(confidence),\n",
    "        \"raw_score\": float(prediction)\n",
    "    }\n",
    "\n",
    "# Test the model with a sample image\n",
    "if len(test_files) > 0:\n",
    "    sample_img = test_files[0]\n",
    "    result = predict_cancer(sample_img)\n",
    "    print(f\"Sample prediction for {sample_img}:\")\n",
    "    print(result)\n",
    "\n",
    "print(\"Model training and saving complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d137fe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745c5d74",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1098e6c5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7129c164",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb5223",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bce46b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93de531b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
